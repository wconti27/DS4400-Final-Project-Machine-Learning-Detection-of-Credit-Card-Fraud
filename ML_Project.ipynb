{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq220dP-rATf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "05bc3e3e-c0e4-4abe-d9e4-fc7748193fab"
      },
      "source": [
        "#!pip install tscv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tscv\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/4b/4f583b6cd0bf06595d14dbbc9310b809bff4e02be232044aeca16bf81e7b/tscv-0.1.1-py3-none-any.whl\n",
            "Installing collected packages: tscv\n",
            "Successfully installed tscv-0.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmSs3i72_jHr"
      },
      "source": [
        "- Collect average transaction size for a credit card\n",
        "- Average longitude and latitude of transactions\n",
        "- Average time of transaction\n",
        "- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0dGWa4YF8RH",
        "outputId": "c78255e5-b87c-4e0d-c78d-fa91d9ec0270"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsZbho0eF99A"
      },
      "source": [
        "folder_location = '/content/gdrive/MyDrive/Colab Notebooks/DS4400: ML Project/' \n",
        "# training = pd.read_csv(folder_location + 'fraudTrain.csv')  \n",
        "# testing = pd.read_csv(folder_location + 'fraudTest.csv')\n",
        "X_train = pd.read_csv(folder_location + 'X_train_eng.csv').drop([\"Unnamed: 0\", \"is_fraud\"], axis=1)\n",
        "y_train = pd.read_csv(folder_location + 'y_train.csv').drop([\"Unnamed: 0\"], axis=1)  \n",
        "X_test = pd.read_csv(folder_location + 'X_test_agg.csv').drop([\"Unnamed: 0\", \"is_fraud\"], axis=1)  \n",
        "y_test = pd.read_csv(folder_location + 'y_test.csv').drop([\"Unnamed: 0\"], axis=1)   \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EIvRlXKiJP5V",
        "outputId": "14d7f2cb-df89-473e-a052-d6a5cf93459c"
      },
      "source": [
        "testing.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>trans_date_trans_time</th>\n",
              "      <th>cc_num</th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>amt</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>gender</th>\n",
              "      <th>street</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zip</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>job</th>\n",
              "      <th>dob</th>\n",
              "      <th>trans_num</th>\n",
              "      <th>unix_time</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>is_fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-06-21 12:14:25</td>\n",
              "      <td>2291163933867244</td>\n",
              "      <td>fraud_Kirlin and Sons</td>\n",
              "      <td>personal_care</td>\n",
              "      <td>2.86</td>\n",
              "      <td>Jeff</td>\n",
              "      <td>Elliott</td>\n",
              "      <td>M</td>\n",
              "      <td>351 Darlene Green</td>\n",
              "      <td>Columbia</td>\n",
              "      <td>SC</td>\n",
              "      <td>29209</td>\n",
              "      <td>33.9659</td>\n",
              "      <td>-80.9355</td>\n",
              "      <td>333497</td>\n",
              "      <td>Mechanical engineer</td>\n",
              "      <td>1968-03-19</td>\n",
              "      <td>2da90c7d74bd46a0caf3777415b3ebd3</td>\n",
              "      <td>1371816865</td>\n",
              "      <td>33.986391</td>\n",
              "      <td>-81.200714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-06-21 12:14:33</td>\n",
              "      <td>3573030041201292</td>\n",
              "      <td>fraud_Sporer-Keebler</td>\n",
              "      <td>personal_care</td>\n",
              "      <td>29.84</td>\n",
              "      <td>Joanne</td>\n",
              "      <td>Williams</td>\n",
              "      <td>F</td>\n",
              "      <td>3638 Marsh Union</td>\n",
              "      <td>Altonah</td>\n",
              "      <td>UT</td>\n",
              "      <td>84002</td>\n",
              "      <td>40.3207</td>\n",
              "      <td>-110.4360</td>\n",
              "      <td>302</td>\n",
              "      <td>Sales professional, IT</td>\n",
              "      <td>1990-01-17</td>\n",
              "      <td>324cc204407e99f51b0d6ca0055005e7</td>\n",
              "      <td>1371816873</td>\n",
              "      <td>39.450498</td>\n",
              "      <td>-109.960431</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-06-21 12:14:53</td>\n",
              "      <td>3598215285024754</td>\n",
              "      <td>fraud_Swaniawski, Nitzsche and Welch</td>\n",
              "      <td>health_fitness</td>\n",
              "      <td>41.28</td>\n",
              "      <td>Ashley</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>F</td>\n",
              "      <td>9333 Valentine Point</td>\n",
              "      <td>Bellmore</td>\n",
              "      <td>NY</td>\n",
              "      <td>11710</td>\n",
              "      <td>40.6729</td>\n",
              "      <td>-73.5365</td>\n",
              "      <td>34496</td>\n",
              "      <td>Librarian, public</td>\n",
              "      <td>1970-10-21</td>\n",
              "      <td>c81755dbbbea9d5c77f094348a7579be</td>\n",
              "      <td>1371816893</td>\n",
              "      <td>40.495810</td>\n",
              "      <td>-74.196111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-06-21 12:15:15</td>\n",
              "      <td>3591919803438423</td>\n",
              "      <td>fraud_Haley Group</td>\n",
              "      <td>misc_pos</td>\n",
              "      <td>60.05</td>\n",
              "      <td>Brian</td>\n",
              "      <td>Williams</td>\n",
              "      <td>M</td>\n",
              "      <td>32941 Krystal Mill Apt. 552</td>\n",
              "      <td>Titusville</td>\n",
              "      <td>FL</td>\n",
              "      <td>32780</td>\n",
              "      <td>28.5697</td>\n",
              "      <td>-80.8191</td>\n",
              "      <td>54767</td>\n",
              "      <td>Set designer</td>\n",
              "      <td>1987-07-25</td>\n",
              "      <td>2159175b9efe66dc301f149d3d5abf8c</td>\n",
              "      <td>1371816915</td>\n",
              "      <td>28.812398</td>\n",
              "      <td>-80.883061</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-06-21 12:15:17</td>\n",
              "      <td>3526826139003047</td>\n",
              "      <td>fraud_Johnston-Casper</td>\n",
              "      <td>travel</td>\n",
              "      <td>3.19</td>\n",
              "      <td>Nathan</td>\n",
              "      <td>Massey</td>\n",
              "      <td>M</td>\n",
              "      <td>5783 Evan Roads Apt. 465</td>\n",
              "      <td>Falmouth</td>\n",
              "      <td>MI</td>\n",
              "      <td>49632</td>\n",
              "      <td>44.2529</td>\n",
              "      <td>-85.0170</td>\n",
              "      <td>1126</td>\n",
              "      <td>Furniture designer</td>\n",
              "      <td>1955-07-06</td>\n",
              "      <td>57ff021bd3f328f8738bb535c302a31b</td>\n",
              "      <td>1371816917</td>\n",
              "      <td>44.959148</td>\n",
              "      <td>-85.884734</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 trans_date_trans_time  ...  merch_long is_fraud\n",
              "0           0   2020-06-21 12:14:25  ...  -81.200714        0\n",
              "1           1   2020-06-21 12:14:33  ... -109.960431        0\n",
              "2           2   2020-06-21 12:14:53  ...  -74.196111        0\n",
              "3           3   2020-06-21 12:15:15  ...  -80.883061        0\n",
              "4           4   2020-06-21 12:15:17  ...  -85.884734        0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "30fyFZkAtiV5",
        "outputId": "eb8014a3-636a-4d23-f83e-f8fd126ae3f6"
      },
      "source": [
        "# visualize the target variable - clearly our data is highly imbalanced and something must be done to fix this issue\n",
        "g = sns.countplot(testing['is_fraud'])\n",
        "g.set_xticklabels(['Not Fraud','Fraud'])\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c3ad7c3f6203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# visualize the target variable - clearly our data is highly imbalanced and something must be done to fix this issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Not Fraud'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Seoh3iLCB3"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BzipXgSd__i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsy33ucGXf_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1KlsP_7Z4sb"
      },
      "source": [
        "from time import mktime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def normalize_features(X_train, X_test):\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_scaled = pd.DataFrame(data=scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "  X_test_scaled = pd.DataFrame(data=scaler.transform(X_test), columns=X_train.columns)\n",
        "  return X_train_scaled, X_test_scaled\n",
        "\n",
        "def engineer_datetime(df):\n",
        "  df[\"datetime\"] = df[\"trans_date_trans_time\"].apply(pd.to_datetime)\n",
        "  df[\"hour\"] = df[\"datetime\"].dt.hour\n",
        "  df[\"day\"] = df[\"datetime\"].dt.day\n",
        "  df[\"month\"] = df[\"datetime\"].dt.month\n",
        "  df[\"unix_purchase_time\"] = df[\"datetime\"].apply(lambda dt: mktime(dt.timetuple()))\n",
        "  dob_dt = df[\"dob\"].apply(pd.to_datetime)\n",
        "  dob_year = dob_dt.dt.year \n",
        "  df[\"dob_year\"] = dob_year\n",
        "  df[\"unix_dob\"] = dob_dt.apply(lambda dt: mktime(dt.timetuple()))\n",
        "  df = df.drop([\"trans_date_trans_time\", \"dob\"], axis=1)\n",
        "  return df\n",
        "\n",
        "def engineer_features(df):\n",
        "  df = engineer_datetime(df)\n",
        "  df = df.drop([\"state\", \"city\", \"Unnamed: 0\", \"merchant\", \"first\", \"last\", \"street\", \"zip\", \"job\", \"unix_time\"], axis=1)\n",
        "  df[\"is_man\"] = df[\"gender\"].apply(lambda x: 0 if x == \"F\" else 1)\n",
        "  df = df.drop(\"gender\", axis=1)\n",
        "  df.reset_index(inplace=True)\n",
        "  #df = pd.DataFrame(df, dtype={'amt': float, 'lat': float, 'long': float, 'city_pop': float, 'merch_lat': float, 'merch_long': float})\n",
        "  df = df.astype({'amt': float, 'lat': float, 'long': float, 'city_pop': float, 'merch_lat': float, 'merch_long': float})\n",
        "  obj_df = df.select_dtypes(include=['object']).copy()\n",
        "  obj_df_encoded = pd.get_dummies(obj_df, columns=[\"category\"], prefix=[\"category\"])\n",
        "  df = df.drop([\"category\"], axis=1)\n",
        "  obj_df_encoded.reset_index(inplace=True)\n",
        "  df = pd.concat([df,obj_df_encoded],axis=1).drop(\"index\", axis=1)\n",
        "  df = df.loc[:,~df.columns.duplicated()]\n",
        "  means = df.apply(concat_averages, frame=df, axis=1)\n",
        "  df = df.merge(means, left_on='trans_num', right_on='trans_num')\n",
        "  df.drop(['datetime', 'cc_num', 'trans_num'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    d = {}\n",
        "    d['amt_mean'] = x['amt'].mean()\n",
        "    d['amt_std'] = x['amt'].std()\n",
        "    d['amt_count'] = x['amt'].count()\n",
        "    d['merch_lat_mean'] = x['merch_lat'].mean()\n",
        "    d['merch_lat_std'] = x['merch_lat'].std()\n",
        "    d['merch_long_mean'] = x['merch_long'].mean()\n",
        "    d['merch_long_std'] = x['merch_long'].std()\n",
        "    d['is_fraud_mean'] = x['is_fraud'].mean()\n",
        "    d['is_fraud_std'] = x['is_fraud'].std()\n",
        "    d['previous_frauds_for_cc_num'] = d['amt_count'] * d['is_fraud_mean']\n",
        "    return pd.Series(d, index=['amt_mean', 'amt_std', 'amt_count', 'merch_lat_mean', 'merch_lat_std', 'merch_long_mean', 'merch_long_std', 'is_fraud_mean', 'is_fraud_std', 'previous_frauds_for_cc_num'])\n",
        "\n",
        "def concat_averages(row, frame):\n",
        "  date = row['datetime']\n",
        "  cc_num = row['cc_num']\n",
        "  frame_before_date = frame.loc[ (frame[\"cc_num\"] == cc_num) & (frame['datetime'] < date)].copy()\n",
        "  frame_before_date.drop(columns=['city_pop', 'lat', 'long'], inplace=True)\n",
        "  cc_averages = frame_before_date.groupby(\"cc_num\").apply(f)\n",
        "  cc_averages = cc_averages.fillna(0)\n",
        "  indices = ['amt_mean', 'amt_std', 'amt_count', 'merch_lat_mean', 'merch_lat_std', 'merch_long_mean', 'merch_long_std', 'is_fraud_mean', 'is_fraud_std', 'previous_frauds_for_cc_num']\n",
        "  if len(cc_averages.values) == 0:\n",
        "    zeros = np.zeros(len(indices))\n",
        "    series = pd.Series(zeros, index=indices)\n",
        "  else:\n",
        "    series = pd.Series(cc_averages.values[0], index=indices)\n",
        "  series['trans_num'] = row['trans_num']\n",
        "  return series\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-tAiEoWmq0a",
        "outputId": "0a6f0b37-f4b8-495e-d270-11aec5059783"
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "y_train = training[\"is_fraud\"]\n",
        "X_train = training.drop([\"is_fraud\"], axis = 1)\n",
        "\n",
        "# summarize class distribution\n",
        "print(\"Before undersampling: \", Counter(y_train))\n",
        "\n",
        "# define undersampling strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy=.1)\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "# summarize class distribution\n",
        "print(\"After undersampling: \", Counter(y_train_under))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Before undersampling:  Counter({0: 1289169, 1: 7506})\n",
            "After undersampling:  Counter({0: 75060, 1: 7506})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "LuEYPcprM8mE",
        "outputId": "c8cd30ff-786a-4496-d2e5-08cf03cba6ba"
      },
      "source": [
        "#PART 2\n",
        "# import SVM libraries \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train_unused, X_test, y_train, y_test = train_test_split(testing.drop([\"is_fraud\"], axis=1), testing[\"is_fraud\"], test_size = 0.1)\n",
        "\n",
        "X_train_under_df = pd.DataFrame(X_train_under, columns=training.drop([\"is_fraud\"], axis=1).columns)\n",
        "X_test_df = pd.DataFrame(X_test, columns=training.drop([\"is_fraud\"], axis=1).columns)\n",
        "X_train_under_df['is_fraud'] = y_train_under\n",
        "print(X_train_under_df.shape, X_test_df.shape)\n",
        "X_train_under_df = engineer_features(X_train_under_df)\n",
        "X_test_df['is_fraud'] = y_test\n",
        "X_test_df = engineer_features(X_test_df)\n",
        "\n",
        "X_train_under_df.drop('is_fraud', axis=1, inplace=True)\n",
        "X_test_df.drop('is_fraud', axis=1, inplace=True)\n",
        "\n",
        "X_train_under_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-04e7796728e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx_train_unused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_fraud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_fraud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_train_under_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_under\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_fraud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testing' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWXqQ1J_gl3c"
      },
      "source": [
        "def create_aggregated_df_to_apply_to_test(train_df):\n",
        "  lat_long_df = train_df[['lat', 'long', 'amt_count']]\n",
        "  lat_long_df_agg = lat_long_df.groupby(['lat', 'long']).agg('max')\n",
        "  lat_long_df_agg.set_index(['amt_count'], append=True, inplace=True)\n",
        "  lat_long_df_agg.head()\n",
        "  indices = ['lat', 'long', 'amt_mean', 'amt_std', 'amt_count', 'merch_lat_mean', 'merch_lat_std', 'merch_long_mean', 'merch_long_std', 'is_fraud_mean', 'is_fraud_std', 'previous_frauds_for_cc_num']\n",
        "  cc_averages_by_lat = train_df[indices]\n",
        "  cc_averages_by_lat.set_index(['lat', 'long', 'amt_count'], inplace=True)\n",
        "  df_with_maxes = pd.merge(lat_long_df_agg, cc_averages_by_lat, left_index=True, right_index=True, how=\"inner\")\n",
        "  df_with_maxes.reset_index(level='amt_count', inplace=True)\n",
        "  return df_with_maxes\n",
        "\n",
        "agg_df_to_apply_to_test = create_aggregated_df_to_apply_to_test(X_train_under_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ps3x5AMp-Bg"
      },
      "source": [
        "def map_aggregations(row, frame):\n",
        "  lat = row['lat']\n",
        "  long = row['long']\n",
        "  if (lat, long) not in frame.index:\n",
        "    return row\n",
        "  else:\n",
        "    frame_row = frame.loc[(lat, long)]\n",
        "    if row['amt_count'] == 0:\n",
        "      row['amt_mean'] = frame_row['amt_mean']\n",
        "      row['amt_std'] = frame_row['amt_std']\n",
        "      row['amt_count'] = frame_row['amt_count']\n",
        "      row['merch_lat_mean'] = frame_row['merch_lat_mean']\n",
        "      row['merch_lat_std'] = frame_row['merch_lat_std']\n",
        "      row['merch_long_mean'] = frame_row['merch_long_mean']\n",
        "      row['merch_long_std'] = frame_row['merch_long_std']\n",
        "      row['is_fraud_mean'] = frame_row['is_fraud_mean']\n",
        "      row['is_fraud_std'] = frame_row['is_fraud_std']\n",
        "      row['previous_frauds_for_cc_num'] = frame_row['previous_frauds_for_cc_num']\n",
        "      return row\n",
        "    else:\n",
        "      test_count = row['amt_count']\n",
        "      frame_row_count = frame_row['amt_count']\n",
        "\n",
        "      row['amt_mean'] = combine_means(row['amt_mean'], frame_row['amt_mean'], test_count, frame_row_count)\n",
        "      row['amt_std'] = combine_std(row['amt_std'], frame_row['amt_std'], test_count, frame_row_count)\n",
        "      row['amt_count'] = test_count + frame_row_count\n",
        "      row['merch_lat_mean'] = combine_means(row['merch_lat_mean'], frame_row['merch_lat_mean'], test_count, frame_row_count)\n",
        "      row['merch_lat_std'] = combine_std(row['merch_lat_std'], frame_row['merch_lat_std'], test_count, frame_row_count)\n",
        "      row['merch_long_mean'] = combine_means(row['merch_long_mean'], frame_row['merch_long_mean'], test_count, frame_row_count)\n",
        "      row['merch_long_std'] = combine_std(row['merch_long_std'], frame_row['merch_long_std'], test_count, frame_row_count)\n",
        "      row['is_fraud_mean'] = combine_means(row['is_fraud_mean'], frame_row['is_fraud_mean'], test_count, frame_row_count)\n",
        "      row['is_fraud_std'] = combine_std(row['is_fraud_std'], frame_row['is_fraud_std'], test_count, frame_row_count)\n",
        "      row['previous_frauds_for_cc_num'] = frame_row['previous_frauds_for_cc_num'] + row['previous_frauds_for_cc_num']\n",
        "      return row\n",
        "\n",
        "def combine_means(mean1, mean2, n1, n2):\n",
        "  return (mean1 * n1 + mean2 * n2) / (n1 + n2)\n",
        "\n",
        "def combine_std(std1, std2, n1, n2):\n",
        "  var1 = (std1 ** 2) / n1\n",
        "  var2 = (std2 ** 2) / n2\n",
        "  return np.sqrt((var1 + var2) / 2)   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmi6f57gwb3L"
      },
      "source": [
        "def apply_aggregation_df_to_test(test_df, agg_df):\n",
        "  return test_df.apply(map_aggregations, frame=agg_df, axis=1)\n",
        "\n",
        "X_test_df_agg = apply_aggregation_df_to_test(X_test_df, agg_df_to_apply_to_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koOkl0Xhoszs"
      },
      "source": [
        "def add_blank_columns(df_train, df_test):\n",
        "  for column in df_train.columns:\n",
        "    if column not in df_test.columns:\n",
        "      df_test[column] = 0\n",
        "  for column2 in df_test.columns:\n",
        "    if column2 not in df_train.columns:\n",
        "      df_train[column2] = 0\n",
        "  return df_train, df_test\n",
        "##X_train_under_df, X_test_df = add_blank_columns(X_train_under_df, X_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyPSU8JhkODx"
      },
      "source": [
        "# scaling features \n",
        "\n",
        "X_train_scaled_df, X_test_scaled_df = normalize_features(X_train, X_test)\n",
        "X_train_scaled_df.to_csv(folder_location + \"X_train_aggregated_and_scaled.csv\")\n",
        "X_test_scaled_df.to_csv(folder_location + \"X_test_aggregated_and_scaled.csv\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFCRpODsMt06",
        "outputId": "09745198-70b3-4131-eed5-0a0da1859a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "X_train_scaled_df.tail()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amt</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>dob_year</th>\n",
              "      <th>is_man</th>\n",
              "      <th>category_entertainment</th>\n",
              "      <th>category_food_dining</th>\n",
              "      <th>category_gas_transport</th>\n",
              "      <th>category_grocery_net</th>\n",
              "      <th>category_grocery_pos</th>\n",
              "      <th>category_health_fitness</th>\n",
              "      <th>category_home</th>\n",
              "      <th>category_kids_pets</th>\n",
              "      <th>category_misc_net</th>\n",
              "      <th>category_misc_pos</th>\n",
              "      <th>category_personal_care</th>\n",
              "      <th>category_shopping_net</th>\n",
              "      <th>category_shopping_pos</th>\n",
              "      <th>category_travel</th>\n",
              "      <th>amt_mean</th>\n",
              "      <th>amt_std</th>\n",
              "      <th>amt_count</th>\n",
              "      <th>merch_lat_mean</th>\n",
              "      <th>merch_lat_std</th>\n",
              "      <th>merch_long_mean</th>\n",
              "      <th>merch_long_std</th>\n",
              "      <th>is_fraud_mean</th>\n",
              "      <th>is_fraud_std</th>\n",
              "      <th>previous_frauds_for_cc_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1296670</th>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.379084</td>\n",
              "      <td>0.544346</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.367421</td>\n",
              "      <td>0.551347</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.456790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044096</td>\n",
              "      <td>0.036271</td>\n",
              "      <td>0.484305</td>\n",
              "      <td>0.561719</td>\n",
              "      <td>0.415637</td>\n",
              "      <td>0.322933</td>\n",
              "      <td>0.435419</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.108820</td>\n",
              "      <td>0.473684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296671</th>\n",
              "      <td>0.001751</td>\n",
              "      <td>0.412281</td>\n",
              "      <td>0.902174</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.410026</td>\n",
              "      <td>0.886727</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.679012</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070625</td>\n",
              "      <td>0.042853</td>\n",
              "      <td>0.169763</td>\n",
              "      <td>0.584750</td>\n",
              "      <td>0.426240</td>\n",
              "      <td>0.533288</td>\n",
              "      <td>0.439388</td>\n",
              "      <td>0.015094</td>\n",
              "      <td>0.172596</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296672</th>\n",
              "      <td>0.003625</td>\n",
              "      <td>0.276699</td>\n",
              "      <td>0.612486</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.300969</td>\n",
              "      <td>0.617133</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.530864</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045493</td>\n",
              "      <td>0.048668</td>\n",
              "      <td>0.662716</td>\n",
              "      <td>0.489832</td>\n",
              "      <td>0.409624</td>\n",
              "      <td>0.363194</td>\n",
              "      <td>0.439553</td>\n",
              "      <td>0.005317</td>\n",
              "      <td>0.102868</td>\n",
              "      <td>0.578947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296673</th>\n",
              "      <td>0.002553</td>\n",
              "      <td>0.499837</td>\n",
              "      <td>0.646029</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>0.490098</td>\n",
              "      <td>0.636080</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.691358</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066802</td>\n",
              "      <td>0.033738</td>\n",
              "      <td>0.647982</td>\n",
              "      <td>0.645154</td>\n",
              "      <td>0.415553</td>\n",
              "      <td>0.382865</td>\n",
              "      <td>0.442897</td>\n",
              "      <td>0.003955</td>\n",
              "      <td>0.088779</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296674</th>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.553210</td>\n",
              "      <td>0.530050</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.568003</td>\n",
              "      <td>0.526323</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.876543</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048113</td>\n",
              "      <td>0.027980</td>\n",
              "      <td>0.483985</td>\n",
              "      <td>0.682423</td>\n",
              "      <td>0.422747</td>\n",
              "      <td>0.314591</td>\n",
              "      <td>0.446493</td>\n",
              "      <td>0.005295</td>\n",
              "      <td>0.102664</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              amt       lat  ...  is_fraud_std  previous_frauds_for_cc_num\n",
              "1296670  0.000503  0.379084  ...      0.108820                    0.473684\n",
              "1296671  0.001751  0.412281  ...      0.172596                    0.421053\n",
              "1296672  0.003625  0.276699  ...      0.102868                    0.578947\n",
              "1296673  0.002553  0.499837  ...      0.088779                    0.421053\n",
              "1296674  0.000114  0.553210  ...      0.102664                    0.421053\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEYOtmqR-OuM",
        "outputId": "e0771a2b-4b72-4b2f-e65e-a142089b147a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "X_test_scaled_df.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amt</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>merch_lat</th>\n",
              "      <th>merch_long</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>dob_year</th>\n",
              "      <th>is_man</th>\n",
              "      <th>category_entertainment</th>\n",
              "      <th>category_food_dining</th>\n",
              "      <th>category_gas_transport</th>\n",
              "      <th>category_grocery_net</th>\n",
              "      <th>category_grocery_pos</th>\n",
              "      <th>category_health_fitness</th>\n",
              "      <th>category_home</th>\n",
              "      <th>category_kids_pets</th>\n",
              "      <th>category_misc_net</th>\n",
              "      <th>category_misc_pos</th>\n",
              "      <th>category_personal_care</th>\n",
              "      <th>category_shopping_net</th>\n",
              "      <th>category_shopping_pos</th>\n",
              "      <th>category_travel</th>\n",
              "      <th>amt_mean</th>\n",
              "      <th>amt_std</th>\n",
              "      <th>amt_count</th>\n",
              "      <th>merch_lat_mean</th>\n",
              "      <th>merch_lat_std</th>\n",
              "      <th>merch_long_mean</th>\n",
              "      <th>merch_long_std</th>\n",
              "      <th>is_fraud_mean</th>\n",
              "      <th>is_fraud_std</th>\n",
              "      <th>previous_frauds_for_cc_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.298692</td>\n",
              "      <td>0.867121</td>\n",
              "      <td>0.114727</td>\n",
              "      <td>0.308536</td>\n",
              "      <td>0.857102</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049069</td>\n",
              "      <td>0.043602</td>\n",
              "      <td>0.499680</td>\n",
              "      <td>0.505779</td>\n",
              "      <td>0.411062</td>\n",
              "      <td>0.512953</td>\n",
              "      <td>0.445257</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>0.631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.434867</td>\n",
              "      <td>0.565239</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.421239</td>\n",
              "      <td>0.568699</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.814815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.061434</td>\n",
              "      <td>0.668802</td>\n",
              "      <td>0.600080</td>\n",
              "      <td>0.418344</td>\n",
              "      <td>0.335279</td>\n",
              "      <td>0.449110</td>\n",
              "      <td>0.006705</td>\n",
              "      <td>0.115440</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001391</td>\n",
              "      <td>0.442414</td>\n",
              "      <td>0.942836</td>\n",
              "      <td>0.011860</td>\n",
              "      <td>0.442800</td>\n",
              "      <td>0.927345</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.567901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062305</td>\n",
              "      <td>0.045513</td>\n",
              "      <td>0.825112</td>\n",
              "      <td>0.605235</td>\n",
              "      <td>0.416657</td>\n",
              "      <td>0.557376</td>\n",
              "      <td>0.440261</td>\n",
              "      <td>0.002717</td>\n",
              "      <td>0.073635</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002040</td>\n",
              "      <td>0.183058</td>\n",
              "      <td>0.868312</td>\n",
              "      <td>0.018834</td>\n",
              "      <td>0.201817</td>\n",
              "      <td>0.860288</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040411</td>\n",
              "      <td>0.063186</td>\n",
              "      <td>0.488469</td>\n",
              "      <td>0.425210</td>\n",
              "      <td>0.416574</td>\n",
              "      <td>0.513605</td>\n",
              "      <td>0.437670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.519129</td>\n",
              "      <td>0.825355</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>0.534860</td>\n",
              "      <td>0.810131</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.044441</td>\n",
              "      <td>0.038202</td>\n",
              "      <td>0.651185</td>\n",
              "      <td>0.658598</td>\n",
              "      <td>0.412812</td>\n",
              "      <td>0.488217</td>\n",
              "      <td>0.433355</td>\n",
              "      <td>0.005411</td>\n",
              "      <td>0.103770</td>\n",
              "      <td>0.578947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        amt       lat  ...  is_fraud_std  previous_frauds_for_cc_num\n",
              "0  0.000064  0.298692  ...      0.123596                    0.631579\n",
              "1  0.000996  0.434867  ...      0.115440                    0.736842\n",
              "2  0.001391  0.442414  ...      0.073635                    0.368421\n",
              "3  0.002040  0.183058  ...      0.000000                    0.000000\n",
              "4  0.000076  0.519129  ...      0.103770                    0.578947\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPzi0f1m1y7q",
        "outputId": "65e84314-3b30-4c44-b7fe-9ae013a345c3"
      },
      "source": [
        "print(np.isnan(X_train_scaled_df.any())) #and gets False\n",
        "print(np.isfinite(X_train_scaled_df.all()))\n",
        "print(np.isnan(np.min(X_train_scaled_df)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTDZii-ukxch",
        "outputId": "0cb1699a-e027-4dec-b365-557e69a0004c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Feature Research - Running Random Forest for Feature Importances\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ybhOekZkx-8",
        "outputId": "b3ddf88c-8c16-4ed8-cdb1-15f83f697f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "rf.feature_importances_\n",
        "feature_importances = pd.DataFrame(rf.feature_importances_, index=X_train.columns)\n",
        "feature_importances.to_csv(folder_location + \"RF_feature_importances.csv\")\n",
        "sorted_idx = rf.feature_importances_.argsort()\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.barh(X_train.columns, rf.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Random Forest Feature Importance\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Random Forest Feature Importance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD6fvkaikySz",
        "outputId": "a7644453-ab61-468c-9f26-dd068adb85fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Perform cross validation to get preliminary best models\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tscv import GapWalkForward\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def perform_cross_validation(metrics_df, model, model_name, X_training, y_training):\n",
        "  tscv = GapWalkForward(n_splits=10, gap_size=0, test_size=10000)\n",
        "\n",
        "  g_means = []\n",
        "  f1s = []\n",
        "  f2s = []\n",
        "  precisions = []\n",
        "  recalls = []\n",
        "  accuracies = []\n",
        "  errors = []\n",
        "\n",
        "  for train_index, test_index in tscv.split(X_training):\n",
        "    X_train, X_test = X_training.iloc[train_index], X_training.iloc[test_index]\n",
        "    y_train, y_test = y_training.iloc[train_index], y_training.iloc[test_index]\n",
        "\n",
        "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    f2 = fbeta_score(y_test, predictions, beta=2)\n",
        "\n",
        "    # print(confusion_matrix(y_test, predictions))\n",
        "    # print(classification_report(y_test, predictions))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
        "\n",
        "    recall = tp / (tp + fn)\n",
        "    specificity = tn / (fp + tn)\n",
        "    precision = tp / (tp + fp)\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
        "\n",
        "    g_mean = np.sqrt(recall * specificity)\n",
        "\n",
        "    f1s.append(f1)\n",
        "    f2s.append(f2)\n",
        "    g_means.append(g_mean)\n",
        "    recalls.append(recall)\n",
        "    precisions.append(precision)\n",
        "    accuracies.append(accuracy)\n",
        "    errors.append(1- accuracy)\n",
        "  \n",
        "  print(f1s, f2s, g_means, precisions, recalls)\n",
        "  metrics_df.loc[model_name] = [np.mean(f1s), np.mean(f2s), np.mean(g_means), np.mean(recalls), np.mean(precisions), np.mean(accuracies), np.mean(errors)]\n",
        "\n",
        "  return model, metrics_df\n",
        "\n",
        "def compare_models(models, model_names, X_training, y_training, X_testing, y_testing):\n",
        "  cross_validation_model_scores = pd.DataFrame(data=None, columns = [\"Model Name\", \"F1-Score\", \"F2-Score\", \"G-Mean\", \"Recall for 1\", \"Precision for 1\", \"Accuracy\", \"Error\"])\n",
        "  cross_validation_model_scores.set_index('Model Name', inplace=True)\n",
        "  for i in range(len(models)):\n",
        "    model, cross_validation_model_scores = perform_cross_validation(cross_validation_model_scores, models[i], model_names[i], X_training, y_training)\n",
        "    predictions = model.predict(X_testing)\n",
        "    print(confusion_matrix(y_testing, predictions))\n",
        "    print(classification_report(y_testing, predictions))\n",
        "  return cross_validation_model_scores\n",
        "\n",
        "model_names = [\"LogRegression\", \"LDA\", \"Naive Bayes\", \"Decision Trees\", \"kNN\", \"SVM\", \"Random Forest\", \"XGBoost\", \"AdaBoost\"]\n",
        "some_model_names = [\"LogReg\", \"Random Forest\", \"AdaBoost\", \"Decision Trees\", \"SVC\"]\n",
        "some_models = [LogisticRegression(random_state=0, max_iter=2000), RandomForestClassifier(n_estimators=100, random_state=0), AdaBoostClassifier(n_estimators = 100, random_state=0), DecisionTreeClassifier(random_state=0), SVC(random_state=0)]\n",
        "\n",
        "compare_models(some_models, some_model_names, X_train_scaled_df.tail(300000), y_train.tail(300000), X_test_scaled_df.head(100000), y_test.head(100000))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 35) (10000, 35) (200000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(210000, 35) (10000, 35) (210000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(220000, 35) (10000, 35) (220000, 1) (10000, 1)\n",
            "(230000, 35) (10000, 35) (230000, 1) (10000, 1)\n",
            "(240000, 35) (10000, 35) (240000, 1) (10000, 1)\n",
            "(250000, 35) (10000, 35) (250000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(260000, 35) (10000, 35) (260000, 1) (10000, 1)\n",
            "(270000, 35) (10000, 35) (270000, 1) (10000, 1)\n",
            "(280000, 35) (10000, 35) (280000, 1) (10000, 1)\n",
            "(290000, 35) (10000, 35) (290000, 1) (10000, 1)\n",
            "[0.0, 0.0, 0.03125, 0.26315789473684215, 0.0, 0.0, 0.3076923076923077, 0.06666666666666667, 0.2857142857142857, 0.015037593984962407] [0.0, 0.0, 0.019762845849802372, 0.18450184501845018, 0.0, 0.0, 0.2173913043478261, 0.04273504273504274, 0.19999999999999996, 0.00945179584120983] [0.0, 0.0, 0.12598815766974242, 0.3922125298566029, 0.0, 0.0, 0.4264014327112209, 0.18569533817705186, 0.408248290463863, 0.08703882797784893] [nan, nan, 1.0, 0.9090909090909091, 0.0, nan, 1.0, 1.0, 1.0, 1.0] [0.0, 0.0, 0.015873015873015872, 0.15384615384615385, 0.0, 0.0, 0.18181818181818182, 0.034482758620689655, 0.16666666666666666, 0.007575757575757576]\n",
            "[[99595     3]\n",
            " [  351    51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     99598\n",
            "           1       0.94      0.13      0.22       402\n",
            "\n",
            "    accuracy                           1.00    100000\n",
            "   macro avg       0.97      0.56      0.61    100000\n",
            "weighted avg       1.00      1.00      1.00    100000\n",
            "\n",
            "(200000, 35) (10000, 35) (200000, 1) (10000, 1)\n",
            "(210000, 35) (10000, 35) (210000, 1) (10000, 1)\n",
            "(220000, 35) (10000, 35) (220000, 1) (10000, 1)\n",
            "(230000, 35) (10000, 35) (230000, 1) (10000, 1)\n",
            "(240000, 35) (10000, 35) (240000, 1) (10000, 1)\n",
            "(250000, 35) (10000, 35) (250000, 1) (10000, 1)\n",
            "(260000, 35) (10000, 35) (260000, 1) (10000, 1)\n",
            "(270000, 35) (10000, 35) (270000, 1) (10000, 1)\n",
            "(280000, 35) (10000, 35) (280000, 1) (10000, 1)\n",
            "(290000, 35) (10000, 35) (290000, 1) (10000, 1)\n",
            "[0.7123287671232876, 0.7719298245614036, 0.8392857142857143, 0.8907563025210083, 0.9714285714285714, 0.8421052631578948, 0.7777777777777778, 0.8846153846153846, 0.72, 0.7428571428571429] [0.6074766355140188, 0.6853582554517134, 0.7807308970099668, 0.8439490445859872, 0.9550561797752809, 0.7692307692307693, 0.6862745098039215, 0.827338129496403, 0.6164383561643836, 0.6435643564356436] [0.74376843799781, 0.7985092036083578, 0.8636443676207207, 0.9029410520380264, 0.97182531580755, 0.8528028654224418, 0.7977240352174656, 0.8905635565617213, 0.75, 0.7687061147858074] [1.0, 0.9777777777777777, 0.9591836734693877, 0.9814814814814815, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] [0.5531914893617021, 0.6376811594202898, 0.746031746031746, 0.8153846153846154, 0.9444444444444444, 0.7272727272727273, 0.6363636363636364, 0.7931034482758621, 0.5625, 0.5909090909090909]\n",
            "[[ 4627 94971]\n",
            " [   11   391]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.05      0.09     99598\n",
            "           1       0.00      0.97      0.01       402\n",
            "\n",
            "    accuracy                           0.05    100000\n",
            "   macro avg       0.50      0.51      0.05    100000\n",
            "weighted avg       0.99      0.05      0.09    100000\n",
            "\n",
            "(200000, 35) (10000, 35) (200000, 1) (10000, 1)\n",
            "(210000, 35) (10000, 35) (210000, 1) (10000, 1)\n",
            "(220000, 35) (10000, 35) (220000, 1) (10000, 1)\n",
            "(230000, 35) (10000, 35) (230000, 1) (10000, 1)\n",
            "(240000, 35) (10000, 35) (240000, 1) (10000, 1)\n",
            "(250000, 35) (10000, 35) (250000, 1) (10000, 1)\n",
            "(260000, 35) (10000, 35) (260000, 1) (10000, 1)\n",
            "(270000, 35) (10000, 35) (270000, 1) (10000, 1)\n",
            "(280000, 35) (10000, 35) (280000, 1) (10000, 1)\n",
            "(290000, 35) (10000, 35) (290000, 1) (10000, 1)\n",
            "[0.4722222222222222, 0.5599999999999999, 0.673469387755102, 0.7857142857142858, 0.8421052631578948, 0.42857142857142855, 0.6896551724137931, 0.7037037037037037, 0.6666666666666667, 0.6010362694300517] [0.39906103286384975, 0.4560260586319218, 0.5749128919860628, 0.7166123778501629, 0.8695652173913043, 0.3191489361702128, 0.5952380952380952, 0.6737588652482269, 0.5707762557077627, 0.4923599320882852] [0.6011750157277518, 0.6369258327957584, 0.7236740272528789, 0.822629121393028, 0.9426201208224105, 0.5222329678670935, 0.7384746787989444, 0.8091836423391245, 0.7216153159787361, 0.6627671973905228] [0.68, 0.9032258064516129, 0.9428571428571428, 0.9361702127659575, 0.8, 1.0, 0.9375, 0.76, 0.9259259259259259, 0.9508196721311475] [0.3617021276595745, 0.4057971014492754, 0.5238095238095238, 0.676923076923077, 0.8888888888888888, 0.2727272727272727, 0.5454545454545454, 0.6551724137931034, 0.5208333333333334, 0.4393939393939394]\n",
            "[[99573    25]\n",
            " [  257   145]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     99598\n",
            "           1       0.85      0.36      0.51       402\n",
            "\n",
            "    accuracy                           1.00    100000\n",
            "   macro avg       0.93      0.68      0.75    100000\n",
            "weighted avg       1.00      1.00      1.00    100000\n",
            "\n",
            "(200000, 35) (10000, 35) (200000, 1) (10000, 1)\n",
            "(210000, 35) (10000, 35) (210000, 1) (10000, 1)\n",
            "(220000, 35) (10000, 35) (220000, 1) (10000, 1)\n",
            "(230000, 35) (10000, 35) (230000, 1) (10000, 1)\n",
            "(240000, 35) (10000, 35) (240000, 1) (10000, 1)\n",
            "(250000, 35) (10000, 35) (250000, 1) (10000, 1)\n",
            "(260000, 35) (10000, 35) (260000, 1) (10000, 1)\n",
            "(270000, 35) (10000, 35) (270000, 1) (10000, 1)\n",
            "(280000, 35) (10000, 35) (280000, 1) (10000, 1)\n",
            "(290000, 35) (10000, 35) (290000, 1) (10000, 1)\n",
            "[0.7045454545454545, 0.8028169014084506, 0.8461538461538461, 0.890625, 0.711111111111111, 0.8909090909090909, 0.631578947368421, 0.7428571428571429, 0.7191011235955055, 0.7739130434782607] [0.6768558951965065, 0.8166189111747851, 0.8620689655172414, 0.8823529411764706, 0.808080808080808, 0.8909090909090909, 0.5769230769230769, 0.8280254777070064, 0.6866952789699571, 0.7108626198083067] [0.8117338104195357, 0.908160797450586, 0.93378884771914, 0.936158897143793, 0.942289418351601, 0.9435950345328862, 0.7381775357716048, 0.9461516713555125, 0.8161273018199988, 0.8207481275728106] [0.7560975609756098, 0.7808219178082192, 0.8208955223880597, 0.9047619047619048, 0.5925925925925926, 0.8909090909090909, 0.75, 0.6341463414634146, 0.7804878048780488, 0.9081632653061225] [0.6595744680851063, 0.8260869565217391, 0.873015873015873, 0.8769230769230769, 0.8888888888888888, 0.8909090909090909, 0.5454545454545454, 0.896551724137931, 0.6666666666666666, 0.6742424242424242]\n",
            "[[98966   632]\n",
            " [  123   279]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     99598\n",
            "           1       0.31      0.69      0.42       402\n",
            "\n",
            "    accuracy                           0.99    100000\n",
            "   macro avg       0.65      0.84      0.71    100000\n",
            "weighted avg       1.00      0.99      0.99    100000\n",
            "\n",
            "(200000, 35) (10000, 35) (200000, 1) (10000, 1)\n",
            "(210000, 35) (10000, 35) (210000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(220000, 35) (10000, 35) (220000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(230000, 35) (10000, 35) (230000, 1) (10000, 1)\n",
            "(240000, 35) (10000, 35) (240000, 1) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(250000, 35) (10000, 35) (250000, 1) (10000, 1)\n",
            "(260000, 35) (10000, 35) (260000, 1) (10000, 1)\n",
            "(270000, 35) (10000, 35) (270000, 1) (10000, 1)\n",
            "(280000, 35) (10000, 35) (280000, 1) (10000, 1)\n",
            "(290000, 35) (10000, 35) (290000, 1) (10000, 1)\n",
            "[0.08163265306122448, 0.0, 0.0, 0.2666666666666667, 0.0, 0.03571428571428572, 0.3823529411764706, 0.2424242424242424, 0.3157894736842105, 0.02985074626865672] [0.05263157894736842, 0.0, 0.0, 0.18518518518518517, 0.0, 0.02262443438914027, 0.2789699570815451, 0.16666666666666666, 0.22388059701492538, 0.018867924528301886] [0.20628424925175867, 0.0, 0.0, 0.3922322702763681, 0.0, 0.13483997249264842, 0.4861724348043977, 0.3713906763541037, 0.4330127018922193, 0.12309149097933274] [1.0, nan, nan, 1.0, nan, 1.0, 1.0, 1.0, 1.0, 1.0] [0.0425531914893617, 0.0, 0.0, 0.15384615384615385, 0.0, 0.01818181818181818, 0.23636363636363636, 0.13793103448275862, 0.1875, 0.015151515151515152]\n",
            "[[99598     0]\n",
            " [  349    53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     99598\n",
            "           1       1.00      0.13      0.23       402\n",
            "\n",
            "    accuracy                           1.00    100000\n",
            "   macro avg       1.00      0.57      0.62    100000\n",
            "weighted avg       1.00      1.00      1.00    100000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>F2-Score</th>\n",
              "      <th>G-Mean</th>\n",
              "      <th>Recall for 1</th>\n",
              "      <th>Precision for 1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogReg</th>\n",
              "      <td>0.096952</td>\n",
              "      <td>0.067384</td>\n",
              "      <td>0.162558</td>\n",
              "      <td>0.056026</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.99448</td>\n",
              "      <td>0.00552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.815308</td>\n",
              "      <td>0.741542</td>\n",
              "      <td>0.834048</td>\n",
              "      <td>0.700688</td>\n",
              "      <td>0.991844</td>\n",
              "      <td>0.99805</td>\n",
              "      <td>0.00195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.642314</td>\n",
              "      <td>0.566746</td>\n",
              "      <td>0.718130</td>\n",
              "      <td>0.529070</td>\n",
              "      <td>0.883650</td>\n",
              "      <td>0.99671</td>\n",
              "      <td>0.00329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Trees</th>\n",
              "      <td>0.771361</td>\n",
              "      <td>0.773939</td>\n",
              "      <td>0.879693</td>\n",
              "      <td>0.779831</td>\n",
              "      <td>0.781888</td>\n",
              "      <td>0.99757</td>\n",
              "      <td>0.00243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.135443</td>\n",
              "      <td>0.094883</td>\n",
              "      <td>0.214702</td>\n",
              "      <td>0.079153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.99460</td>\n",
              "      <td>0.00540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                F1-Score  F2-Score  ...  Accuracy    Error\n",
              "Model Name                          ...                   \n",
              "LogReg          0.096952  0.067384  ...   0.99448  0.00552\n",
              "Random Forest   0.815308  0.741542  ...   0.99805  0.00195\n",
              "AdaBoost        0.642314  0.566746  ...   0.99671  0.00329\n",
              "Decision Trees  0.771361  0.773939  ...   0.99757  0.00243\n",
              "SVC             0.135443  0.094883  ...   0.99460  0.00540\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8fWLi6ne2AG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eb41e8-d46c-4d44-d2ef-04c4213ccc12"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ROC AUC score for undersampled data:  0.5640515583681343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGfaV9Xf-fxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbyFxK487i0f",
        "outputId": "3057169c-326a-431a-b1b5-5c87d24e5302"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(confusion_matrix(y_test.iloc[0:50000], pred_under))\n",
        "print(classification_report(y_test.iloc[0:50000], pred_under))\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(confusion_matrix(y_train.iloc[0:50000], pred_train))\n",
        "print(classification_report(y_train.iloc[0:50000], pred_train))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[49674   127]\n",
            " [  173    26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     49801\n",
            "           1       0.17      0.13      0.15       199\n",
            "\n",
            "    accuracy                           0.99     50000\n",
            "   macro avg       0.58      0.56      0.57     50000\n",
            "weighted avg       0.99      0.99      0.99     50000\n",
            "\n",
            "--------------------------------------------------------\n",
            "[[47094  2458]\n",
            " [    0   448]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97     49552\n",
            "           1       0.15      1.00      0.27       448\n",
            "\n",
            "    accuracy                           0.95     50000\n",
            "   macro avg       0.58      0.98      0.62     50000\n",
            "weighted avg       0.99      0.95      0.97     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcrKrbZ8_QTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daa8f5b-84fa-4f7e-b4ae-001a117f9fef"
      },
      "source": [
        "\n",
        "\n",
        "ada = AdaBoostClassifier(n_estimators = 100, random_state=0)\n",
        "ada.fit(X_train_scaled_df, y_train_under)\n",
        "pred_test = ada.predict(X_test_scaled_df)\n",
        "pred_train = ada.predict(X_train_scaled_df)\n",
        "print(classification_report(y_test, pred_test))\n",
        "print(classification_report(y_train_under, pred_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     55381\n",
            "           1       0.07      0.78      0.13       191\n",
            "\n",
            "    accuracy                           0.97     55572\n",
            "   macro avg       0.54      0.87      0.56     55572\n",
            "weighted avg       1.00      0.97      0.98     55572\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     75060\n",
            "           1       0.93      0.88      0.91      7506\n",
            "\n",
            "    accuracy                           0.98     82566\n",
            "   macro avg       0.96      0.94      0.95     82566\n",
            "weighted avg       0.98      0.98      0.98     82566\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdzWEtv14XbO",
        "outputId": "6ef42b3d-a4ab-4f0c-c218-10ce1957341a"
      },
      "source": [
        "print(confusion_matrix(y_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[53490  1891]\n",
            " [   42   149]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}